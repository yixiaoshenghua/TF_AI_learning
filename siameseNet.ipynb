{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37464bit38ac3e8de7214f58a93970a1c089ff06",
   "display_name": "Python 3.7.4 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Lambda, Dense, Dropout, Conv2D, MaxPooling2D, Flatten\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 图像对识别\n",
    "\n",
    "import os\n",
    "imglst=os.listdir(r\"G:\\Work\\file\\MNIST\\data_a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = dict(zip([str(i) for i in range(10)],[0]*10))\n",
    "for name in imglst:\n",
    "    nums[name[0]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_sample_size = 10000\n",
    "\n",
    "root_path = r'G:\\Work\\file\\MNIST\\data_a'\n",
    "\n",
    "def get_data(total_sample_size):\n",
    "    #read the image\n",
    "    image = cv2.imread(root_path+\"\\\\1_1.png\", 0)\n",
    "    # image = cv2.resize(image,(56,46),interpolation=cv2.INTER_CUBIC)\n",
    "    #get the new size\n",
    "    dim1 = image.shape[0]\n",
    "    dim2 = image.shape[1]\n",
    "\n",
    "    count = 0\n",
    "    \n",
    "    #initialize the numpy array with the shape of [total_sample, no_of_pairs, dim1, dim2]\n",
    "    x_geuine_pair = np.zeros([total_sample_size, 2, dim1, dim2, 1])  # 2 is for pairs\n",
    "    y_genuine = np.zeros([total_sample_size, 1])\n",
    "    \n",
    "    for i in range(10):\n",
    "        for j in range(int(total_sample_size/10)):\n",
    "            ind1 = 0\n",
    "            ind2 = 0\n",
    "            \n",
    "            #read images from same directory (genuine pair)\n",
    "            while ind1 == ind2:\n",
    "                ind1 = np.random.randint(nums[str(i)])\n",
    "                ind2 = np.random.randint(nums[str(i)])\n",
    "            \n",
    "            # read the two images\n",
    "            img1 = cv2.imread(root_path+\"\\{}_{}.png\".format(i, ind1), 0)\n",
    "            img2 = cv2.imread(root_path+\"\\{}_{}.png\".format(i, ind2), 0)\n",
    "            # img1 = cv2.resize(img1,(56,46),interpolation=cv2.INTER_CUBIC)\n",
    "            # img2 = cv2.resize(img2,(56,46),interpolation=cv2.INTER_CUBIC)\n",
    "            \n",
    "            #store the images to the initialized numpy array\n",
    "            x_geuine_pair[count, 0, :, :, 0] = img1\n",
    "            x_geuine_pair[count, 1, :, :, 0] = img2\n",
    "            \n",
    "            #as we are drawing images from the same directory we assign label as 1. (genuine pair)\n",
    "            y_genuine[count] = 1\n",
    "            count += 1\n",
    "\n",
    "    count = 0\n",
    "    x_imposite_pair = np.zeros([total_sample_size, 2, dim1, dim2, 1])\n",
    "    y_imposite = np.zeros([total_sample_size, 1])\n",
    "    \n",
    "    for i in range(int(total_sample_size/10)):\n",
    "        for j in range(10):\n",
    "            \n",
    "            #read images from different directory (imposite pair)\n",
    "            while True:\n",
    "                ind1 = np.random.randint(10)\n",
    "                ind2 = np.random.randint(10)\n",
    "                if ind1 != ind2:\n",
    "                    break\n",
    "                    \n",
    "            img1 = cv2.imread(root_path+'\\{}_{}.png'.format(ind1, j), 0)\n",
    "            img2 = cv2.imread(root_path+'\\{}_{}.png'.format(ind2, j), 0)\n",
    "            # img1 = cv2.resize(img1,(56,46),interpolation=cv2.INTER_CUBIC)\n",
    "            # img2 = cv2.resize(img2,(56,46),interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "\n",
    "            x_imposite_pair[count, 0, :, :, 0] = img1\n",
    "            x_imposite_pair[count, 1, :, :, 0] = img2\n",
    "            #as we are drawing images from the different directory we assign label as 0. (imposite pair)\n",
    "            y_imposite[count] = 0\n",
    "            count += 1\n",
    "            \n",
    "    #now, concatenate, genuine pairs and imposite pair to get the whole data\n",
    "    X = np.concatenate([x_geuine_pair, x_imposite_pair], axis=0)/255\n",
    "    Y = np.concatenate([y_genuine, y_imposite], axis=0)\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "X shape: (20000, 2, 28, 28, 1)\nY shape: (20000, 1)\n"
     ]
    }
   ],
   "source": [
    "X, Y = get_data(total_sample_size)\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"Y shape:\", Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_base_network(input_shape):\n",
    "    \n",
    "    seq = Sequential()\n",
    "    kernel_size = 2\n",
    "    \n",
    "    #convolutional layer 1\n",
    "    seq.add(Conv2D(4, kernel_size, kernel_size, input_shape=input_shape,  data_format='channels_last', padding='valid', activation='relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2)))  \n",
    "    seq.add(Dropout(.25))\n",
    "    \n",
    "    #convolutional layer 2\n",
    "    # seq.add(Conv2D(nb_filter[1], kernel_size, kernel_size, padding='valid',  data_format='channels_first', activation='relu'))\n",
    "    # seq.add(MaxPooling2D(pool_size=(2, 2), data_format='channels_first')) \n",
    "    # seq.add(Dropout(.25))\n",
    "\n",
    "    #flatten \n",
    "    seq.add(Flatten())\n",
    "    seq.add(Dense(128, activation='relu'))\n",
    "    seq.add(Dropout(0.1))\n",
    "    seq.add(Dense(50, activation='relu'))\n",
    "    seq.summary()\n",
    "\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_11\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_11 (Conv2D)           (None, 14, 14, 4)         20        \n_________________________________________________________________\nmax_pooling2d_8 (MaxPooling2 (None, 7, 7, 4)           0         \n_________________________________________________________________\ndropout_16 (Dropout)         (None, 7, 7, 4)           0         \n_________________________________________________________________\nflatten_8 (Flatten)          (None, 196)               0         \n_________________________________________________________________\ndense_16 (Dense)             (None, 128)               25216     \n_________________________________________________________________\ndropout_17 (Dropout)         (None, 128)               0         \n_________________________________________________________________\ndense_17 (Dense)             (None, 50)                6450      \n=================================================================\nTotal params: 31,686\nTrainable params: 31,686\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_dim = x_train.shape[2:]\n",
    "input_a = Input(shape=input_dim)\n",
    "input_b = Input(shape=input_dim)\n",
    "\n",
    "base_network = build_base_network(input_dim)\n",
    "feat_vecs_a = base_network(input_a)\n",
    "feat_vecs_b = base_network(input_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    return K.sqrt(K.sum(K.square(x-y), axis=1, keepdims=True))\n",
    "\n",
    "def eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = Lambda(euclidean_distance, output_shape=eucl_dist_output_shape)([feat_vecs_a, feat_vecs_b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "rms = RMSprop()\n",
    "\n",
    "model = Model(inputs=[input_a, input_b], outputs=distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_loss(y_true, y_pred):\n",
    "    margin = 1\n",
    "    return K.mean(y_true*K.square(y_pred)+(1-y_true)*K.square(K.maximum(margin-y_pred, 0)))\n",
    "\n",
    "model.compile(loss=contrastive_loss, optimizer=rms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/5\n",
      "100/100 - 1s - loss: 0.1882 - val_loss: 0.1256\n",
      "Epoch 2/5\n",
      "100/100 - 1s - loss: 0.1345 - val_loss: 0.0912\n",
      "Epoch 3/5\n",
      "100/100 - 1s - loss: 0.1090 - val_loss: 0.0721\n",
      "Epoch 4/5\n",
      "100/100 - 1s - loss: 0.0920 - val_loss: 0.0562\n",
      "Epoch 5/5\n",
      "100/100 - 1s - loss: 0.0780 - val_loss: 0.0433\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x232cf0d7448>"
      ]
     },
     "metadata": {},
     "execution_count": 73
    }
   ],
   "source": [
    "img_1 = x_train[:, 0]\n",
    "img_2 = x_train[:, 1]\n",
    "\n",
    "model.fit([img_1, img_2], y_train, validation_split=0.2, batch_size=128, verbose=2, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9921491658488715"
      ]
     },
     "metadata": {},
     "execution_count": 74
    }
   ],
   "source": [
    "pred = model.predict([x_test[:, 0], x_test[:, 1]])\n",
    "def compute_accuracy(pred, labels):\n",
    "    return labels[pred.ravel() < 0.5].mean()\n",
    "\n",
    "compute_accuracy(pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}